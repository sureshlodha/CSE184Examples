{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is string a:  this \tis \tsome \ttext        with\n",
      "\n",
      " lots of spaces \n",
      "\n",
      "this is string b:               this line\t has some \t space in the front \n",
      "\n",
      "This is string a after splitting the spaces:\n",
      " ['this', 'is', 'some', 'text', 'with', 'lots', 'of', 'spaces']\n",
      "\n",
      "Notice that string b has some space in the front. Notice that there is an empty string in the 0th index\n",
      " ['', 'this', 'line', 'has', 'some', 'space', 'in', 'the', 'front']\n",
      "\n",
      "\n",
      "Just using split with no arguments ['this', 'line', 'has', 'some', 'space', 'in', 'the', 'front']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# splitting means if more than one space\n",
    "# \\s means a whitespace character: [ \\t\\n\\x0B\\f\\r]\n",
    "\n",
    "a = \"this \\tis \\tsome \\ttext        with\\n\\n lots of spaces\"\n",
    "b = \"             this line\\t has some \\t space in the front\"\n",
    "print(\"this is string a: \", a, \"\\n\")\n",
    "print(\"this is string b: \", b, \"\\n\")\n",
    "\n",
    "clean_a = re.split('\\s+', a)\n",
    "print(\"This is string a after splitting the spaces:\\n\", clean_a)\n",
    "\n",
    "clean_b = re.split('\\s+', b)\n",
    "print(\"\\nNotice that string b has some space in the front. Notice that there is an empty string in the 0th index\\n\", clean_b)\n",
    "\n",
    "cleaner_b = b.split()\n",
    "print(\"\\n\\nJust using split with no arguments\", cleaner_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decimal numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is string one:  Some of the numbers of e are: 2.7182818284590452353 the first few of pi are: 3.1415926535 \n",
      "\n",
      "\n",
      "Using the regex '\\d+' all the digits found in the string are put int a list.\n",
      "Notice that the decimal was also taken out. We have to be careful of this when\n",
      "dealing with regexes and decimal numbers\n",
      " ['2', '7182818284590452353', '3', '1415926535']\n",
      "\n",
      "Using the regex '\\d\\.\\d+' we were able to get the correct values we wanted as you can see here:\n",
      " ['2.7182818284590452353', '3.1415926535']\n"
     ]
    }
   ],
   "source": [
    "one = \"Some of the numbers of e are: 2.7182818284590452353 the first few of pi are: 3.1415926535\"\n",
    "print(\"This is string one: \", one, \"\\n\")\n",
    "\n",
    "num_one = re.findall('\\d+', one)\n",
    "print(\"\\nUsing the regex '\\d+' all the digits found in the string are put int a list.\\nNotice that the decimal was also taken out. We have to be careful of this when\\ndealing with regexes and decimal numbers\\n\", num_one)\n",
    "\n",
    "with_dec = re.findall('\\d\\.\\d+', one)\n",
    "print(\"\\nUsing the regex '\\d\\.\\d+' we were able to get the correct values we wanted as you can see here:\\n\", with_dec)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the search function lets us find only the first occurence of a matching\n",
      " a\n",
      "\n",
      "Using the findall function, wecan find all occurrences of the letter a\n",
      " ['a', 'a', 'a', 'a', 'a']\n",
      "\n",
      "In the string, find a part where it starts with 'qui'and give us the next two letters\n",
      " quick\n",
      "\n",
      "You can search without having to consider cases\n",
      " LIQUOR\n",
      "\n",
      "Finding a string based on what we want in the middle\n",
      " quick brown fox\n"
     ]
    }
   ],
   "source": [
    "letters1 = \"The quick brown fox jumps over the lazy dog\"\n",
    "letters2=\"PACK MY BOX WITH FIVE DOZEN LIQUOR JUGS.\"\n",
    "pattern = \"a a a a a b b b b c c c d d e\"\n",
    "\n",
    "find_a = re.search('a', pattern)\n",
    "print(\"\\nUsing the search function lets us find only the first occurence of a matching\\n\", find_a[0])\n",
    "\n",
    "find_all_a = re.findall('a+', pattern)\n",
    "print(\"\\nUsing the findall function, wecan find all occurrences of the letter a\\n\",find_all_a)\n",
    "\n",
    "find_some_a = re.search('qui.{2}', letters1)\n",
    "print(\"\\nIn the string, find a part where it starts with 'qui'and give us the next two letters\\n\", find_some_a[0])\n",
    "\n",
    "pattern2 = r'(?i)liquor'\n",
    "y = re.search(pattern2, letters2)\n",
    "print(\"\\nYou can search without having to consider cases\\n\", y[0])\n",
    "\n",
    "z = re.search(r'q.*.x', letters1)\n",
    "print(\"\\nFinding a string based on what we want in the middle\\n\",z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More in-depth tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for getting data from the google sheet found at the following link\n",
    "# https://socraticowl.com/post/integrate-google-sheets-and-jupyter-notebooks/\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './cs184_presentation.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b162605bb657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'https://spreadsheets.google.com/feeds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServiceAccountCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_keyfile_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cs184_presentation.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/oauth2client/service_account.py\u001b[0m in \u001b[0;36mfrom_json_keyfile_name\u001b[0;34m(cls, filename, scopes, token_uri, revoke_uri)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mthe\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mclient_credentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         return cls._from_parsed_json_keyfile(client_credentials, scopes,\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cs184_presentation.json'"
     ]
    }
   ],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('./cs184_presentation.json')\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheet_key = '155KiZXYhOaPJkmg-KdoYOW497xMX13itjix3rkESjkg'\n",
    "book = gc.open_by_key(spreadsheet_key)\n",
    "worksheet = book.worksheet(\"Sheet1\")\n",
    "table = worksheet.get_all_values()\n",
    "table\n",
    "\n",
    "worksheet2 = book.worksheet(\"area_codes\")\n",
    "table2 = worksheet2.get_all_values()\n",
    "table2\n",
    "\n",
    "##Convert table data into a dataframe\n",
    "df = pd.DataFrame(table[1:], columns=table[0])\n",
    "df2 = pd.DataFrame(table2[1:], columns=table2[0])\n",
    "\n",
    "#print out the first five rows of the dataframe\n",
    "#df.head()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't forget to import re for regular expressions. It's kinda the point of this tutorial \n",
    "import re\n",
    "\n",
    "#Column First: just a name\n",
    "#Column Unclean values: The first character is an ascii value between 33 and 126, so it's\n",
    "#   still readable characters like \"!@#$%^&*()<>\" but it also includes alphabetic and numeric values.\n",
    "\n",
    "#case 1: weird characters (luckily) only showed up at the beginning or end\n",
    "#If we know our result should look like xxx.xxxxxx like how floats look, then weird characters\n",
    "#can show up before or after the decimal with numbers we care able either preceding or succeeding it\n",
    "\n",
    "one_way = []\n",
    "two_way = []\n",
    "three_way = []\n",
    "four_way = []\n",
    "\n",
    "# 1 or more digits followed by one decimal (you need the \\ as an escape character)\n",
    "# followed by one or more digits after it\n",
    "one = r'[0-9]+\\.[0-9]*'\n",
    "\n",
    "# the \\d means the set of digits, A.K.A [0-9]. Again, we have the \\. to represent a .\n",
    "# followed by at least one digit\n",
    "two = r'\\d+\\.\\d*'\n",
    "\n",
    "# ^ this carrot means \"the start of the regular expression\"\n",
    "# \\D is basically (not)\\d, so it catches everything that isn't a digit like weird characters,\n",
    "# punctuation, etc. This regular expression finds a non-numeric character at the beginning of the\n",
    "# expression\n",
    "three = r'^\\D'\n",
    "\n",
    "for row in df['Unclean values']:\n",
    "    # Search for the regex we defined in variable \"one\" in the string defined by our row variable\n",
    "    # get the 0th element in the resulting match object, cast it as a float and append to the\n",
    "    # one_way list.\n",
    "    # note: this works here because there's only one thing we need to search for -the first and only\n",
    "    # unclean value\n",
    "    one_way.append(re.search(one, row)[0])\n",
    "#     print(re.search(one, row)[0])\n",
    "    \n",
    "    # Similar to what we've been doing in assignments, find all instances where the string defined\n",
    "    # by our row variable matches the regex we defined in variable \"two.\" Take the 0th element of this\n",
    "    # resulting list, cast it as a float and append it to the two_way list\n",
    "    two_way.append(re.findall(two, row)[0])\n",
    "#     print(re.findall(two, row)[0])\n",
    "    \n",
    "    # Remember the variable \"three\" has the regex '^\\D'. Using the sub(stitute) function, we\n",
    "    # find the regex in the row and if it matches, we replace it with nothing. That is, if the\n",
    "    # first character is not a digit, substitute it with the empty string\n",
    "    three_way.append(re.sub(three, '', row))\n",
    "#     print(re.sub(three, '', row))\n",
    "    \n",
    "    # The split function does pretty much what you'd expect. It will look at the string in our\n",
    "    # row variable, see if it matches the regular expression, and split the string there.\n",
    "    # This only works because we know how the unclean value is formatted though!\n",
    "    # If the first character is not a decimal value, then the first element in the list is '' and the second\n",
    "    # would be the value we want. If the first character is a decimal value, then the first element in the list\n",
    "    # is what we want to append. As such, we can get this element by appending the -1st element in the list.\n",
    "    # That is, the last element in the list.\n",
    "    four_way.append(re.split(three, row)[-1])\n",
    "#     print(re.split(three, row))\n",
    "\n",
    "df[\"one_way\"] = one_way\n",
    "df[\"two_way\"] = two_way\n",
    "df[\"three_way\"] = three_way\n",
    "df[\"four_way\"] = four_way\n",
    "\n",
    "# If you look at the table the one_way and two_way column has less digits than the three_way and\n",
    "# four_way one, but don't worry, it has the same values. We can print it out above if you wanna check\n",
    "# I think it shows up like that so it'd fit on the page\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 2: Characters we don't want are intermingled with ones we do\n",
    "# We know that we only want english letters\n",
    "\n",
    "\n",
    "# Column More unclean values: this column, unlike the one before, has letters and weird characters\n",
    "#   mixed in between. The weird characters are random unicode values so they may be what we want but also not.\n",
    "\n",
    "# Find strings made of just letters. Cases doesn't matter\n",
    "zulu = r'[a-zA-Z]'\n",
    "yankee = r'[^a-zA-z]'\n",
    "\n",
    "# search, findall, sub, split\n",
    "\n",
    "zu = []\n",
    "ya = []\n",
    "xr = []\n",
    "wh = []\n",
    "\n",
    "for row in df['More unclean values']:\n",
    "\n",
    "    # We used a search in the last cleaning example because we knew only one was dirty,\n",
    "    # but here, there's multiple to find. Using this code, we will only find the first alphabetical values we \n",
    "    # want, but nothing else.\n",
    "    zu.append(re.search(zulu, row)[0])\n",
    "    \n",
    "    # Here, we're finding all instances where the string in the row variable match the regex we gave zulu\n",
    "    # that is, we're getting all the a-z characters, mapping the str function to all of them to make sure they're\n",
    "    # strings, and joining them all together with ''. Afterwards, we append it to the zu list.\n",
    "    yan = ''.join(re.findall(zulu, row))\n",
    "    ya.append(yan)\n",
    "\n",
    "    # Here, like in the previous example, we substitute values we don't want with an empty string and append\n",
    "    # them to the list\n",
    "    xra = re.sub(yankee, '', row)\n",
    "    xr.append(xra)\n",
    "    \n",
    "    # we didn't have to do this in the previous example with the split function, but here, we need to get\n",
    "    # all the values we found with the split, join them together with nothing in between, and then append them\n",
    "#     whi = re.split(yankee, row)\n",
    "    whi = ''.join(re.split(yankee, row))\n",
    "    wh.append(whi)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "df[\"zulu\"] = zu\n",
    "df[\"yankee\"] = ya\n",
    "df[\"xray\"] = xr\n",
    "df[\"whisky\"] = wh\n",
    "df\n",
    "# df.iloc[:,0-2] \n",
    "df[['Name', 'More unclean values', 'zulu', 'yankee', 'xray', 'whisky']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column phone numbers: I picked a handful of area codes and then slapped on some numbers.\n",
    "\n",
    "area_code = []\n",
    "# In order to find characters such as ) and ( we need to use the \\ escape character\n",
    "# Using the {3} we're specifying that we want only 3 digits\n",
    "find_area_code = r'\\([0-9]{3}\\)'\n",
    "for row in df['phone numbers']:\n",
    "    string_val = re.findall(find_area_code, row)[0]\n",
    "    area_code.append(int(string_val[1:-1]))\n",
    "\n",
    "print(area_code)\n",
    "df[\"area code\"] = area_code\n",
    "df[['Name', 'phone numbers', 'area code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Name', 'emojis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_emojis = r'\\(+[^a-zA-z]+\\)+|\\:\\)|\\:\\(|ORZ|OTZ|XD|OAO|\\(+[^a-zA-z].*ω.*\\)+|\\(+[^a-zA-z].*ᴗ.*\\)+|\\(+[^a-zA-z].*ᵕ.*\\)+'\n",
    "is_emoji = []\n",
    "emoji_is = []\n",
    "\n",
    "for row in df['emojis']:\n",
    "    emoj = re.findall(find_emojis, row)\n",
    "    if emoj:\n",
    "        is_emoji.append(\"true\")\n",
    "        emoji_is.append(emoj)\n",
    "    else:\n",
    "        is_emoji.append(\"false\")\n",
    "        emoji_is.append(\"couldn't find\")\n",
    "df[\"is_emoji\"] = is_emoji\n",
    "df[\"emoji_is\"] = emoji_is\n",
    "df[['Name','emojis','is_emoji', 'emoji_is']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
