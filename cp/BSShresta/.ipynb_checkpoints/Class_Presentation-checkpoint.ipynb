{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Selenium & Python to scrape LinkedIn profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-req:<br>\n",
    "1.<br>\n",
    "pip3 install ipython <br> \n",
    "pip3 install selenium  <br>\n",
    "pip3 install time <br>\n",
    "pip3 install parsel<br>\n",
    "pip3 install csv<br>\n",
    "<br>\n",
    "2.<br>\n",
    "Chrome driver - https://sites.google.com/a/chromium.org/chromedriver/downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/shresta/views/UCSC-CMPS184/Class_Presentation', '/Users/shrestabs/anaconda3/lib/python37.zip', '/Users/shrestabs/anaconda3/lib/python3.7', '/Users/shrestabs/anaconda3/lib/python3.7/lib-dynload', '', '/Users/shrestabs/.local/lib/python3.7/site-packages', '/Users/shrestabs/anaconda3/lib/python3.7/site-packages', '/Users/shrestabs/anaconda3/lib/python3.7/site-packages/aeosa', '/Users/shrestabs/anaconda3/lib/python3.7/site-packages/IPython/extensions', '/Users/shrestabs/.ipython', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Users/shrestabs/bin/', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Users/shrestabs/bin/', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Users/shrestabs/bin/', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Users/shrestabs/bin/', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Users/shrestabs/bin/', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Users/shrestabs/bin/', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Users/shrestabs/bin/']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# the package agate supports only version 3.6\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages')\n",
    "# download and copy chromedriver to your home dir\n",
    "sys.path.append('/Users/shrestabs/bin/')\n",
    "print(sys.path)\n",
    "# Make chromedriver available to this code\n",
    "print(os.path.isfile('/Users/shrestabs/bin/chromedriver'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import web driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# specifies the path to the chromedriver binary\n",
    "driver = webdriver.Chrome('/Users/shrestabs/bin/chromedriver')\n",
    "#chrome_options.add_argument('/Users/<username>/Library/Application Support/Google/Chrome/Default'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# driver.get method() will navigate to a page given by the URL address\n",
    "# Blocking call get()\n",
    "# Example 1\n",
    "#driver.get('https://www.linkedinn.com')\n",
    "# Example 2\n",
    "driver.get('https://www.linkedin.com/uas/login?trk=guest_homepage-basic_nav-header-signin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad example: \n",
    "# driver.get('https://photricity.com/flw/ajax/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# ChromePath Plugin install\n",
    "# find username box\n",
    "username = driver.find_element_by_xpath(\"//input[@id='username']\")\n",
    "# send_keys() to simulate key strokes\n",
    "username.send_keys('translinqs@gmail.com')\n",
    "\n",
    "# sleep for 0.5 seconds\n",
    "time.sleep(0.5)\n",
    "\n",
    "# locate password form by_class_name\n",
    "password =  driver.find_element_by_xpath(\"//input[@id='password']\")\n",
    "\n",
    "# send_keys() to simulate key strokes\n",
    "password.send_keys('Class184demo')\n",
    "time.sleep(0.5)\n",
    "\n",
    "# locate submit button by_xpath\n",
    "sign_in_button = driver.find_element_by_xpath('//*[@type=\"submit\"]')\n",
    "\n",
    "# .click() to mimic button click\n",
    "sign_in_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining new variable passing two parameters\n",
    "import csv\n",
    "from pathlib import Path\n",
    "filename = 'employee_details.csv'\n",
    "# To force append mode we can ensure file is present\n",
    "Path(filename).touch()\n",
    "# Decide how you want to store your data. We use w+ mode for now\n",
    "if os.path.exists(filename):\n",
    "    append_write = 'a' # append if already exists\n",
    "else:\n",
    "    append_write = 'w+' # make a new file if not\n",
    "f = open(filename, 'w+', newline='\\n')\n",
    "writer = csv.writer(f , delimiter=',')\n",
    "writer.writerow(['Name', 'Job Title', 'Company', 'College', 'Location', 'URL'])\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use another tab if required with\n",
    "#driver.execute_script(\"window.open('https://www.google.com')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of queries you want to scrape information from \n",
    "driver.get('https://www.google.com')\n",
    "# locate search form by_name\n",
    "search_query = driver.find_element_by_name('q')\n",
    "\n",
    "# send_keys() to simulate the search text key strokes\n",
    "search_query.send_keys('site:linkedin.com/in/ AND \"University Recruiter\" AND \"bay area\"')\n",
    "\n",
    "# .send_keys() to simulate the return key \n",
    "search_query.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate URL by_class_name\n",
    "# Advertisement reject\n",
    "linkedin_urls = driver.find_elements_by_class_name('iUh30')\n",
    "# variable linkedin_url is equal to the list comprehension \n",
    "linkedin_urls = [url.text for url in linkedin_urls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.linkedin.com/in/paulinenlam', 'https://www.linkedin.com/in/dpenapen', 'https://www.linkedin.com/in/marlene-guardado-36318153', 'https://www.linkedin.com/in/emily-vogel-b29bb458', 'https://www.linkedin.com/in/kristen-harris-a973a62', 'https://www.linkedin.com/in/genevieveogara', 'https://www.linkedin.com/in/lauren-zabel-62399210', 'https://www.linkedin.com/in/sarah-field-b2489199', 'https://www.linkedin.com/in/adrianaigarcia', 'https://www.linkedin.com/in/farihanaveed']\n",
      "<class 'list'>\n",
      "<generator object <genexpr> at 0x109615660>\n"
     ]
    }
   ],
   "source": [
    "# to print all elements within our list \n",
    "print(linkedin_urls)\n",
    "\n",
    "# list of url objects is obtained \n",
    "print (type(linkedin_urls))\n",
    "\n",
    "print (url.text for url in linkedin_urls)\n",
    "\n",
    "# print the first value  \n",
    "#linkedin_urls[0].text  \n",
    "\n",
    "# print the second value  \n",
    "#linkedin_urls[1].text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop here if necessary\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsel import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Pauline Lam\n",
      "Job Title: University Recruiter at Wish\n",
      "Company: Wish\n",
      "College: University of Arizona\n",
      "Location: San Francisco Bay Area\n",
      "URL: https://www.linkedin.com/in/paulinenlam\n",
      "\n",
      "\n",
      "Name: Catalina Peña Peñaloza\n",
      "Job Title: .\n",
      "Company: Not Found\n",
      "College: University of Nebraska-Lincoln\n",
      "Location: San Francisco, California\n",
      "URL: https://www.linkedin.com/in/dpenapen\n",
      "\n",
      "\n",
      "Name: Marlene Guardado\n",
      "Job Title: University Recruiter at Stripe\n",
      "Company: Stripe\n",
      "College: CEA Global Education\n",
      "Location: San Francisco Bay Area\n",
      "URL: https://www.linkedin.com/in/marlene-guardado-36318153\n",
      "\n",
      "\n",
      "Name: Emily Vogel\n",
      "Job Title: Manager, University Recruiting and Employment Brand at Box\n",
      "Company: Box\n",
      "College: Stanford University\n",
      "Location: Redwood City, California\n",
      "URL: https://www.linkedin.com/in/emily-vogel-b29bb458\n",
      "\n",
      "\n",
      "Name: Kristen Harris\n",
      "Job Title: University Recruiter at NetApp\n",
      "Company: NetApp\n",
      "College: Hampton University\n",
      "Location: San Francisco Bay Area\n",
      "URL: https://www.linkedin.com/in/kristen-harris-a973a62\n",
      "\n",
      "\n",
      "Name: Genevieve O'Gara\n",
      "Job Title: University Recruiter Program Lead at Plaid\n",
      "Company: Plaid\n",
      "College: Davidson College\n",
      "Location: San Francisco Bay Area\n",
      "URL: https://www.linkedin.com/in/genevieveogara\n",
      "\n",
      "\n",
      "Name: Lauren Zabel\n",
      "Job Title: University Recruiter at Twitter\n",
      "Company: Twitter\n",
      "College: University of California, Santa Barbara\n",
      "Location: San Francisco Bay Area\n",
      "URL: https://www.linkedin.com/in/lauren-zabel-62399210\n",
      "\n",
      "\n",
      "Name: Sarah Field\n",
      "Job Title: University Recruiter at Western Digital\n",
      "Company: Western Digital\n",
      "College: San Jose State University\n",
      "Location: Santa Clara, California\n",
      "URL: https://www.linkedin.com/in/sarah-field-b2489199\n",
      "\n",
      "\n",
      "Name: Adriana I. Garcia\n",
      "Job Title: University Recruiter at Facebook\n",
      "Company: Facebook\n",
      "College: Loyola Marymount University\n",
      "Location: San Francisco Bay Area\n",
      "URL: https://www.linkedin.com/in/adrianaigarcia\n",
      "\n",
      "\n",
      "Name: Fariha N.\n",
      "Job Title: Sr. University Recruiter\n",
      "Company: Twitter\n",
      "College: University of California, Davis\n",
      "Location: San Francisco Bay Area\n",
      "URL: https://www.linkedin.com/in/farihanaveed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For loop to iterate over each URL in the list\n",
    "for linkedin_url in linkedin_urls:\n",
    "\n",
    "    # get the profile URL \n",
    "    driver.get(linkedin_url)\n",
    "\n",
    "    # add a 5 second pause loading each URL\n",
    "    time.sleep(5)\n",
    "\n",
    "    # assigning the source code for the webpage to variable sel\n",
    "    sel = Selector(text=driver.page_source) \n",
    "\n",
    "    # xpath to extract the text from the class containing the name\n",
    "    name = sel.xpath('//*[starts-with(@class, \"pv-top-card-section__name\")]/text()').extract_first()\n",
    "\n",
    "    if name:\n",
    "        name = name.strip()\n",
    "    else:\n",
    "        name = \"Not Found\"\n",
    "\n",
    "\n",
    "    # xpath to extract the text from the class containing the job title\n",
    "    job_title = sel.xpath('//*[starts-with(@class, \"pv-top-card-section__headline\")]/text()').extract_first()\n",
    "\n",
    "    if job_title:\n",
    "        job_title = job_title.strip()\n",
    "    else:\n",
    "        job_title = \"Not Found\"\n",
    "\n",
    "\n",
    "    # xpath to extract the text from the class containing the company\n",
    "    company = sel.xpath('//*[starts-with(@class, \"pv-top-card-v2-section__entity-name pv-top-card-v2-section__company-name\")]/text()').extract_first()\n",
    "\n",
    "    if company:\n",
    "        company = company.strip()\n",
    "    else:\n",
    "        company = \"Not Found\"\n",
    "\n",
    "\n",
    "    # xpath to extract the text from the class containing the college\n",
    "    college = sel.xpath('//*[starts-with(@class, \"pv-top-card-v2-section__entity-name pv-top-card-v2-section__school-name\")]/text()').extract_first()\n",
    "\n",
    "    if college:\n",
    "        college = college.strip()\n",
    "    else:\n",
    "        college = \"Not Found\"\n",
    "\n",
    "\n",
    "    # xpath to extract the text from the class containing the location\n",
    "    location = sel.xpath('//*[starts-with(@class, \"pv-top-card-section__location\")]/text()').extract_first()\n",
    "\n",
    "    if location:\n",
    "        location = location.strip()\n",
    "    else:\n",
    "         location = \"Not Found\"\n",
    "    \n",
    "        \n",
    "        \n",
    "    # Printing to console window\n",
    "    # printing the output to the terminal\n",
    "    print('Name: ' + name)\n",
    "    print('Job Title: ' + job_title)\n",
    "    print('Company: ' + company)\n",
    "    print('College: ' + college)\n",
    "    print('Location: ' + location)\n",
    "    print('URL: ' + linkedin_url)\n",
    "    print('\\n')\n",
    "\n",
    "   # writing the corresponding values to the header\n",
    "    writer.writerow([name, job_title, company, college,location, linkedin_url])\n",
    "    f.flush()\n",
    "\n",
    "    linkedin_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future work\n",
    "# More pages in Google\n",
    "# Limitation 1000 profiles of LinkedIn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV experiments\n",
    "import csv\n",
    "from pathlib import Path\n",
    "filename = 'junk.csv'\n",
    "Path(filename).touch()\n",
    "if os.path.exists(filename):\n",
    "    append_write = 'a' # append if already exists\n",
    "else:\n",
    "    append_write = 'w+' # make a new file if not\n",
    "f = open(filename, append_write, newline='\\n')\n",
    "writer = csv.writer(f , delimiter=',')\n",
    "\n",
    "writer.writerow(['Name', 'Job Title', 'Company', 'College', 'Location', 'URL'])\n",
    "f.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
